{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K04m2Qk23Ouq",
        "outputId": "6b12236d-cfaf-4518-b3be-81cacf9aba51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: glen in /usr/local/lib/python3.10/dist-packages (1.5)\n",
            "Requirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.10/dist-packages (from glen) (2.2.1+cu121)\n",
            "Requirement already satisfied: transformers>=4.30.2 in /usr/local/lib/python3.10/dist-packages (from glen) (4.38.2)\n",
            "Requirement already satisfied: pytorch-transformers>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from glen) (1.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers>=1.2.0->glen) (1.25.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers>=1.2.0->glen) (1.34.84)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers>=1.2.0->glen) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers>=1.2.0->glen) (4.66.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers>=1.2.0->glen) (2023.12.25)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers>=1.2.0->glen) (0.1.99)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers>=1.2.0->glen) (0.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->glen) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->glen) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->glen) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->glen) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->glen) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->glen) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->glen) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->glen) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->glen) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->glen) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->glen) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->glen) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->glen) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->glen) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->glen) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->glen) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->glen) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->glen) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.1->glen) (12.4.127)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.2->glen) (0.20.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.2->glen) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.2->glen) (6.0.1)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.2->glen) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.2->glen) (0.4.2)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.84 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch-transformers>=1.2.0->glen) (1.34.84)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch-transformers>=1.2.0->glen) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch-transformers>=1.2.0->glen) (0.10.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.1->glen) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers>=1.2.0->glen) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers>=1.2.0->glen) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers>=1.2.0->glen) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers>=1.2.0->glen) (2024.2.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->pytorch-transformers>=1.2.0->glen) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->pytorch-transformers>=1.2.0->glen) (1.4.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.1->glen) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.84->boto3->pytorch-transformers>=1.2.0->glen) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.84->boto3->pytorch-transformers>=1.2.0->glen) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install glen\n",
        "from glen import event_detection\n",
        "import os\n",
        "import glob\n",
        "from lxml import etree as ET\n",
        "import csv\n",
        "import json\n",
        "import random\n",
        "import itertools\n",
        "import copy\n",
        "from urllib.parse import urlparse\n",
        "import re\n",
        "import math\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "feAi2Tnz8_xz"
      },
      "outputs": [],
      "source": [
        "def read_json_array(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        json_array = json.load(file)\n",
        "    return json_array\n",
        "\n",
        "def mkdir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "def readCSV(input_file, headers=False):\n",
        "    with open(input_file, 'r',encoding='utf-8') as csvfile:\n",
        "        reader = csv.reader(csvfile)\n",
        "        csv_data = [row for row in reader]\n",
        "        if headers:\n",
        "            csv_data.pop(0)\n",
        "    return csv_data\n",
        "\n",
        "def createCSV(csv_file,data):\n",
        "    with open(csv_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        for row in data:\n",
        "            writer.writerow(row)\n",
        "\n",
        "def writeFile(fileName,content):\n",
        "    mkdir(os.path.dirname(fileName))\n",
        "    with open(fileName, 'w', encoding='utf-8') as f:\n",
        "        f.write(content)\n",
        "\n",
        "def appendFile(fileName,content):\n",
        "    with open(fileName, 'a', encoding='utf-8') as f:\n",
        "        f.write(content+\"\\n\")\n",
        "\n",
        "def readFile(fileName):\n",
        "    with open(fileName, 'r') as file:\n",
        "        contents = file.read()\n",
        "    return contents\n",
        "\n",
        "def createCSV(csv_file,data):\n",
        "    with open(csv_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        for row in data:\n",
        "            writer.writerow(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "6-QCVrvdcjxL"
      },
      "outputs": [],
      "source": [
        "test_data_array=read_json_array(\"./data/test_annotated_unprepared.json\")\n",
        "sentence_list = []\n",
        "empty_sentences=[]\n",
        "for data in test_data_array:\n",
        "  if data[\"sentence\"]!=\"\":\n",
        "    sentence_list.append(data[\"sentence\"])\n",
        "  else:\n",
        "    empty_sentences.append(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NtdvuVtHJGe",
        "outputId": "f570d638-e76e-4f2a-c2d1-46b6448a79b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load model from ./ckpts/trigger_identifier.bin ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Trigger Identificaiton: 100%|██████████| 26/26 [01:04<00:00,  2.48s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load model from ./ckpts/type_ranking.bin ...\n",
            "Predicting 3445 Events ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Candidates: 100%|██████████| 27/27 [00:12<00:00,  2.18it/s]\n",
            "Type Ranking: 100%|██████████| 402/402 [01:33<00:00,  4.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load model from ./ckpts/type_classifier.bin ...\n",
            "Data Processing ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1606it [00:03, 533.08it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "get 10470 predicting data from 1047 events\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Type Classification: 100%|██████████| 164/164 [01:39<00:00,  1.65it/s]\n"
          ]
        }
      ],
      "source": [
        "result = event_detection(sentence_list, './ckpts', bs_TI=64, bs_TC=64, bs_TR=4, k=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3esGwurTDXTn",
        "outputId": "acfd7ea8-23e1-4baa-8341-d540d360fb6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total sentences in test dataset: 10627\n",
            "Total non-empty sentences in test dataset: 1606\n",
            "Total empty sentences in test dataset: 9021\n",
            "\n",
            "Total non-empty sentences in test dataset: 1606\n",
            "Total non-empty sentences in test dataset with predictions: 710\n",
            "Total non-empty sentences in test dataset without predictions: 896\n"
          ]
        }
      ],
      "source": [
        "mkdir(\"output\")\n",
        "writeFile(\"./output/test_predictions.json\",str(result))\n",
        "\n",
        "s_count=0\n",
        "f_count=0\n",
        "test_predictions=[[\"sen_id\",\"sentence\",\"predicted_events\"]]\n",
        "for sentenceData in result:\n",
        "  row=[]\n",
        "  row.append(sentenceData[\"sen_id\"])\n",
        "  row.append(sentenceData[\"sentence\"])\n",
        "  events=[]\n",
        "  for prediction in sentenceData[\"predicted_mentions\"]:\n",
        "    events.append(prediction[\"event_type\"][\"name\"])\n",
        "  if len(events)!=0:\n",
        "    s_count=s_count+1\n",
        "  else:\n",
        "    f_count=f_count+1\n",
        "  row.append(\":\".join(events))\n",
        "  test_predictions.append(row)\n",
        "createCSV(\"./output/test_predictions.csv\",test_predictions)\n",
        "\n",
        "print(\"Total sentences in test dataset: \"+str(len(test_data_array)))\n",
        "print(\"Total non-empty sentences in test dataset: \"+str(len(sentence_list)))\n",
        "print(\"Total empty sentences in test dataset: \"+str(len(empty_sentences)))\n",
        "print(\"\")\n",
        "print(\"Total non-empty sentences in test dataset: \"+str(len(sentence_list)))\n",
        "print(\"Total non-empty sentences in test dataset with predictions: \"+str(s_count))\n",
        "print(\"Total non-empty sentences in test dataset without predictions: \"+str(f_count))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "wD1eYZRHN_03"
      },
      "outputs": [],
      "source": [
        "test_data_array=read_json_array(\"./data/train_unprepared.json\")\n",
        "sentence_list = []\n",
        "empty_sentences=[]\n",
        "for data in test_data_array:\n",
        "  if data[\"sentence\"]!=\"\":\n",
        "    sentence_list.append(data[\"sentence\"])\n",
        "  else:\n",
        "    empty_sentences.append(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-cDFDMCOFgN",
        "outputId": "217e28fc-9b16-40ff-ca78-8cea06161b2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load model from ./ckpts/trigger_identifier.bin ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Trigger Identificaiton: 100%|██████████| 421/421 [17:43<00:00,  2.53s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load model from ./ckpts/type_ranking.bin ...\n",
            "Predicting 3445 Events ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Candidates: 100%|██████████| 27/27 [00:12<00:00,  2.15it/s]\n",
            "Type Ranking: 100%|██████████| 6729/6729 [25:51<00:00,  4.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load model from ./ckpts/type_classifier.bin ...\n",
            "Data Processing ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "26914it [00:55, 489.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "get 191730 predicting data from 19173 events\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Type Classification: 100%|██████████| 2996/2996 [30:15<00:00,  1.65it/s]\n"
          ]
        }
      ],
      "source": [
        "result = event_detection(sentence_list, './ckpts', bs_TI=64, bs_TC=64, bs_TR=4, k=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UT4eyPU4OIqH",
        "outputId": "c02c2366-a69a-4190-eb62-c995d7caa6b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total sentences in train dataset: 187468\n",
            "Total non-empty sentences in train dataset: 26914\n",
            "Total empty sentences in train dataset: 160554\n",
            "\n",
            "Total non-empty sentences in train dataset: 26914\n",
            "Total non-empty sentences in train dataset with predictions: 12692\n",
            "Total non-empty sentences in train dataset without predictions: 14222\n"
          ]
        }
      ],
      "source": [
        "mkdir(\"output\")\n",
        "writeFile(\"./output/train_predictions.json\",str(result))\n",
        "\n",
        "s_count=0\n",
        "f_count=0\n",
        "test_predictions=[[\"sen_id\",\"sentence\",\"predicted_events\"]]\n",
        "for sentenceData in result:\n",
        "  row=[]\n",
        "  row.append(sentenceData[\"sen_id\"])\n",
        "  row.append(sentenceData[\"sentence\"])\n",
        "  events=[]\n",
        "  for prediction in sentenceData[\"predicted_mentions\"]:\n",
        "    events.append(prediction[\"event_type\"][\"name\"])\n",
        "  if len(events)!=0:\n",
        "    s_count=s_count+1\n",
        "  else:\n",
        "    f_count=f_count+1\n",
        "  row.append(\":\".join(events))\n",
        "  test_predictions.append(row)\n",
        "createCSV(\"./output/train_predictions.csv\",test_predictions)\n",
        "\n",
        "print(\"Total sentences in train dataset: \"+str(len(test_data_array)))\n",
        "print(\"Total non-empty sentences in train dataset: \"+str(len(sentence_list)))\n",
        "print(\"Total empty sentences in train dataset: \"+str(len(empty_sentences)))\n",
        "print(\"\")\n",
        "print(\"Total non-empty sentences in train dataset: \"+str(len(sentence_list)))\n",
        "print(\"Total non-empty sentences in train dataset with predictions: \"+str(s_count))\n",
        "print(\"Total non-empty sentences in train dataset without predictions: \"+str(f_count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "XbL30qZtgOAg"
      },
      "outputs": [],
      "source": [
        "test_data_array=read_json_array(\"./data/dev_annotated_unprepared.json\")\n",
        "sentence_list = []\n",
        "empty_sentences=[]\n",
        "for data in test_data_array:\n",
        "  if data[\"sentence\"]!=\"\":\n",
        "    sentence_list.append(data[\"sentence\"])\n",
        "  else:\n",
        "    empty_sentences.append(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQ5Ejqnngblj",
        "outputId": "f3f41937-441b-478c-e737-2313288e5050"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load model from ./ckpts/trigger_identifier.bin ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Trigger Identificaiton: 100%|██████████| 22/22 [00:55<00:00,  2.51s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load model from ./ckpts/type_ranking.bin ...\n",
            "Predicting 3445 Events ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Candidates: 100%|██████████| 27/27 [00:12<00:00,  2.16it/s]\n",
            "Type Ranking: 100%|██████████| 350/350 [01:21<00:00,  4.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load model from ./ckpts/type_classifier.bin ...\n",
            "Data Processing ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1398it [00:02, 519.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "get 11140 predicting data from 1114 events\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Type Classification: 100%|██████████| 175/175 [01:45<00:00,  1.65it/s]\n"
          ]
        }
      ],
      "source": [
        "result = event_detection(sentence_list, './ckpts', bs_TI=64, bs_TC=64, bs_TR=4, k=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F92d08YLgfKw",
        "outputId": "62d3a2d7-30dd-446e-aa2c-c57d5283c20c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total sentences in dev dataset: 10359\n",
            "Total non-empty sentences in dev dataset: 1398\n",
            "Total empty sentences in dev dataset: 8961\n",
            "\n",
            "Total non-empty sentences in dev dataset: 1398\n",
            "Total non-empty sentences in dev dataset with predictions: 697\n",
            "Total non-empty sentences in dev dataset without predictions: 701\n"
          ]
        }
      ],
      "source": [
        "mkdir(\"output\")\n",
        "writeFile(\"./output/dev_predictions.json\",str(result))\n",
        "\n",
        "s_count=0\n",
        "f_count=0\n",
        "test_predictions=[[\"sen_id\",\"sentence\",\"predicted_events\"]]\n",
        "for sentenceData in result:\n",
        "  row=[]\n",
        "  row.append(sentenceData[\"sen_id\"])\n",
        "  row.append(sentenceData[\"sentence\"])\n",
        "  events=[]\n",
        "  for prediction in sentenceData[\"predicted_mentions\"]:\n",
        "    events.append(prediction[\"event_type\"][\"name\"])\n",
        "  if len(events)!=0:\n",
        "    s_count=s_count+1\n",
        "  else:\n",
        "    f_count=f_count+1\n",
        "  row.append(\":\".join(events))\n",
        "  test_predictions.append(row)\n",
        "createCSV(\"./output/dev_predictions.csv\",test_predictions)\n",
        "\n",
        "print(\"Total sentences in dev dataset: \"+str(len(test_data_array)))\n",
        "print(\"Total non-empty sentences in dev dataset: \"+str(len(sentence_list)))\n",
        "print(\"Total empty sentences in dev dataset: \"+str(len(empty_sentences)))\n",
        "print(\"\")\n",
        "print(\"Total non-empty sentences in dev dataset: \"+str(len(sentence_list)))\n",
        "print(\"Total non-empty sentences in dev dataset with predictions: \"+str(s_count))\n",
        "print(\"Total non-empty sentences in dev dataset without predictions: \"+str(f_count))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
