{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KW31m4ajTv6",
        "outputId": "a5797953-5f96-4c69-bd23-43cb4ca724af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting googletrans==4.0.0-rc1\n",
            "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting httpx==0.13.3 (from googletrans==4.0.0-rc1)\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.2.2)\n",
            "Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hstspreload-2024.4.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n",
            "Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17395 sha256=77bc85ecc1d5740bd689f68d02cb96b57a7e793800b5ea2c1c55aff023b8b058\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/59/9f/7372f0cf70160fe61b528532e1a7c8498c4becd6bcffb022de\n",
            "Successfully built googletrans\n",
            "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.7\n",
            "    Uninstalling idna-3.7:\n",
            "      Successfully uninstalled idna-3.7\n",
            "Successfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2024.4.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n",
            "Collecting googletrans==3.1.0a0\n",
            "  Downloading googletrans-3.1.0a0.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.10/dist-packages (from googletrans==3.1.0a0) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2024.2.2)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2024.4.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.3.1)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.0.0)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-3.1.0a0-py3-none-any.whl size=16353 sha256=b783a06a8098b14b1a8adb53c70dcdfb5e352b1b55e993740fcb3646f028f92a\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/5d/3c/8477d0af4ca2b8b1308812c09f1930863caeebc762fe265a95\n",
            "Successfully built googletrans\n",
            "Installing collected packages: googletrans\n",
            "  Attempting uninstall: googletrans\n",
            "    Found existing installation: googletrans 4.0.0rc1\n",
            "    Uninstalling googletrans-4.0.0rc1:\n",
            "      Successfully uninstalled googletrans-4.0.0rc1\n",
            "Successfully installed googletrans-3.1.0a0\n",
            "Collecting google_trans_new\n",
            "  Downloading google_trans_new-1.1.9-py3-none-any.whl (9.2 kB)\n",
            "Installing collected packages: google_trans_new\n",
            "Successfully installed google_trans_new-1.1.9\n"
          ]
        }
      ],
      "source": [
        "!pip install googletrans==4.0.0-rc1\n",
        "!pip install googletrans==3.1.0a0\n",
        "!pip install google_trans_new\n",
        "import os\n",
        "import glob\n",
        "from lxml import etree as ET\n",
        "import csv\n",
        "import json\n",
        "import random\n",
        "import itertools\n",
        "import copy\n",
        "from urllib.parse import urlparse\n",
        "import re\n",
        "import math\n",
        "import sys\n",
        "from googletrans import Translator\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vP4ILERSjTv7"
      },
      "outputs": [],
      "source": [
        "def read_json_array(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        json_array = json.load(file)\n",
        "    return json_array\n",
        "\n",
        "def mkdir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "def readCSV(input_file, headers=False):\n",
        "    with open(input_file, 'r',encoding='utf-8') as csvfile:\n",
        "        reader = csv.reader(csvfile)\n",
        "        csv_data = [row for row in reader]\n",
        "        if headers:\n",
        "            csv_data.pop(0)\n",
        "    return csv_data\n",
        "\n",
        "def createCSV(csv_file,data):\n",
        "    with open(csv_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        for row in data:\n",
        "            writer.writerow(row)\n",
        "\n",
        "def writeFile(fileName,content):\n",
        "    mkdir(os.path.dirname(fileName))\n",
        "    with open(fileName, 'w', encoding='utf-8') as f:\n",
        "        f.write(content)\n",
        "\n",
        "def appendFile(fileName,content):\n",
        "    with open(fileName, 'a', encoding='utf-8') as f:\n",
        "        f.write(content+\"\\n\")\n",
        "\n",
        "def readFile(fileName):\n",
        "    with open(fileName, 'r') as file:\n",
        "        contents = file.read()\n",
        "    return contents\n",
        "\n",
        "def translate(sentence, lang):\n",
        "    translator = Translator()\n",
        "    translated = translator.translate(sentence,  src='en', dest=lang).text\n",
        "    return translated\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OVxGUpNijTv8"
      },
      "outputs": [],
      "source": [
        "new_fulldata=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIBBtWb7jTv8",
        "outputId": "f612e969-94d4-4e0b-cd93-ad27fffc3c42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26914/26914 [49:55<00:00,  8.99it/s]\n"
          ]
        }
      ],
      "source": [
        "csvData=readCSV(\"./train_predictions.csv\",True)\n",
        "new_trainData = []\n",
        "for id,row in enumerate(tqdm(csvData)):\n",
        "  if row[2]!=\"\":\n",
        "    if id<len(csvData)/2:\n",
        "      newSen=translate(row[1],\"it\")\n",
        "      newEvents=[]\n",
        "      for event in row[2].split(\":\"):\n",
        "        x=translate(event,\"it\")\n",
        "        newEvents.append(x)\n",
        "      new_trainData.append([row[0],newSen,\":\".join(newEvents)])\n",
        "    else:\n",
        "      new_trainData.append(row)\n",
        "mkdir(\"output\")\n",
        "createCSV(\"output/train_translated.csv\",new_trainData)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byoDl1NcjTv8",
        "outputId": "d804f8e0-6db4-49f3-92c7-5022e23a64a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1606/1606 [03:11<00:00,  8.40it/s]\n"
          ]
        }
      ],
      "source": [
        "csvData=readCSV(\"./test_predictions.csv\",True)\n",
        "new_trainData = []\n",
        "for id,row in enumerate(tqdm(csvData)):\n",
        "  if row[2]!=\"\":\n",
        "    if id<len(csvData)/2:\n",
        "      newSen=translate(row[1],\"it\")\n",
        "      newEvents=[]\n",
        "      for event in row[2].split(\":\"):\n",
        "        x=translate(event,\"it\")\n",
        "        newEvents.append(x)\n",
        "      new_trainData.append([row[0],newSen,\":\".join(newEvents)])\n",
        "    else:\n",
        "      new_trainData.append(row)\n",
        "mkdir(\"output\")\n",
        "createCSV(\"output/test_translated.csv\",new_trainData)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99Mq3O0ijTv8",
        "outputId": "481ff375-6ab2-4252-d073-03f9cefa8ad8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1398/1398 [02:42<00:00,  8.62it/s]\n"
          ]
        }
      ],
      "source": [
        "csvData=readCSV(\"./dev_predictions.csv\",True)\n",
        "new_trainData = []\n",
        "for id,row in enumerate(tqdm(csvData)):\n",
        "  if row[2]!=\"\":\n",
        "    if id<len(csvData)/2:\n",
        "      newSen=translate(row[1],\"it\")\n",
        "      newEvents=[]\n",
        "      for event in row[2].split(\":\"):\n",
        "        x=translate(event,\"it\")\n",
        "        newEvents.append(x)\n",
        "      new_trainData.append([row[0],newSen,\":\".join(newEvents)])\n",
        "    else:\n",
        "      new_trainData.append(row)\n",
        "mkdir(\"output\")\n",
        "createCSV(\"output/dev_translated.csv\",new_trainData)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}